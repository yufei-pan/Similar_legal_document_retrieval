{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\kes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import contractions\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "\n",
    "nltk.download('punkt', quiet = True)\n",
    "nltk.download('wordnet', quiet = True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet = True)\n",
    "nltk.download('stopwords', quiet = True)\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting zstandard\n",
      "  Downloading zstandard-0.19.0-cp310-cp310-win_amd64.whl (473 kB)\n",
      "     -------------------------------------- 473.8/473.8 kB 7.5 MB/s eta 0:00:00\n",
      "Installing collected packages: zstandard\n",
      "Successfully installed zstandard-0.19.0\n"
     ]
    }
   ],
   "source": [
    "! pip install zstandard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using in block processing to make data visualize easier\n",
    "# def preprocess_data(df):\n",
    "#     # lower case\n",
    "#     df['Text'] = df['Text'].str.lower()\n",
    "\n",
    "#     # remove url\n",
    "#     df['Text'] = df['Text'].replace(r'[\\S]+\\.(net|com|org|info|edu|gov|uk|de|ca|jp|fr|au|us|ru|ch|it|nel|se|no|es|mil)[\\S]*\\s?', 'URL', regex=True)\n",
    "\n",
    "#     # remove non-alphabetical\n",
    "#     df['Text'] = df['Text'].str.replace('[^a-zA-Z\\']', ' ', regex=True).str.strip()\n",
    "\n",
    "\n",
    "#     # remove extra spaces\n",
    "#     df['Text'] = df['Text'].str.replace(' +', ' ', regex=True).str.strip()\n",
    "\n",
    "#     # #expand contractions\n",
    "#     df['Text'] = df['Text'].apply(lambda x: contractions.fix(x))\n",
    "#     # df['Text'] = df['Text'].apply(lambda x: [contractions.fix(word) for word in x.split()])\n",
    "#     # #join back words\n",
    "#     # df['Text'] = [' '.join(map(str, l)) for l in X['Text']]\n",
    "\n",
    "#     # #remove html and url form reviews\n",
    "#     # df['Text'] = df['Text'].str.replace(r'\\s*https?://\\S+(\\s+|$)', '', regex=True).str.strip()\n",
    "#     # #remove non-alphabetical characters\n",
    "#     # df['Text'] = df['Text'].str.replace('[^a-zA-Z]', ' ', regex=True)\n",
    "#     # #remove extra spaces\n",
    "#     # df['Text'] = df['Text'].replace(r'\\s+', ' ', regex=True)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_remove_stopwords(X):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    X['tokens'] = X['Text'].apply(tokenize.word_tokenize)\n",
    "    return X['tokens'].apply(lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_tfidf(X):\n",
    "    tfidf=TfidfVectorizer(min_df = 50, max_df=0.95, ngram_range = (1,3), max_features=1500, norm='l2')\n",
    "    X_data = tfidf.fit_transform(X)\n",
    "    return X_data.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv file and convert to dataframe\n",
    "df = pd.read_pickle('data/2019.pkl.zst',compression = 'zstd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    " # remnove nan from the df\n",
    "df = df.dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Docket</th>\n",
       "      <th>Argued</th>\n",
       "      <th>Decided</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AARON J. SCHOCK  v.  UNITED STATES(2019)</td>\n",
       "      <td>No. 18-406</td>\n",
       "      <td></td>\n",
       "      <td>February 19, 2019</td>\n",
       "      <td>United States Supreme Court AARON J. SCHOCK  v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABU-ALI ABDUR'RAHMAN, ET AL.  v.  TONY PARKER,...</td>\n",
       "      <td>No. 18-8332</td>\n",
       "      <td></td>\n",
       "      <td>May 13, 2019</td>\n",
       "      <td>United States Supreme Court ABU-ALI ABDUR'RAHM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIR &amp;AMP; LIQUID SYSTEMS CORP. ET AL. v. DEVRI...</td>\n",
       "      <td>No. 17-1104</td>\n",
       "      <td>October 10, 2018</td>\n",
       "      <td>March 19, 2019</td>\n",
       "      <td>United States Supreme Court AIR &amp;AMP; LIQUID S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMERICAN LEGION ET AL. v. AMERICAN HUMANIST AS...</td>\n",
       "      <td>No. 17-1717</td>\n",
       "      <td>February 27, 2019</td>\n",
       "      <td>June 20, 2019</td>\n",
       "      <td>United States Supreme Court AMERICAN LEGION ET...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>APPLE INC. v. PEPPER ET AL.(2019)</td>\n",
       "      <td>No. 17-204</td>\n",
       "      <td>November 26, 2018</td>\n",
       "      <td>May 13, 2019</td>\n",
       "      <td>United States Supreme Court APPLE INC. v. PEPP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>TIMBS v. INDIANA(2019)</td>\n",
       "      <td>No. 17-1091</td>\n",
       "      <td>November 28, 2018</td>\n",
       "      <td>February 20, 2019</td>\n",
       "      <td>United States Supreme Court TIMBS v. INDIANA(2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>VIRGINIA HOUSE OF DELEGATES ET AL. v. BETHUNE-...</td>\n",
       "      <td>No. 18-281</td>\n",
       "      <td>March 18, 2019</td>\n",
       "      <td>June 17, 2019</td>\n",
       "      <td>United States Supreme Court VIRGINIA HOUSE OF ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>VIRGINIA URANIUM, INC., ET AL. v. WARREN ET AL...</td>\n",
       "      <td>No. 16-1275</td>\n",
       "      <td>November 5, 2018</td>\n",
       "      <td>June 17, 2019</td>\n",
       "      <td>United States Supreme Court VIRGINIA URANIUM, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>WALTER DANIEL, INDIVIDUALLY AND AS PERSONAL RE...</td>\n",
       "      <td>No. 18-460</td>\n",
       "      <td></td>\n",
       "      <td>May 20, 2019</td>\n",
       "      <td>United States Supreme Court WALTER DANIEL, IND...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>WASHINGTON STATE DEPARTMENT OF LICENSING v. CO...</td>\n",
       "      <td>No. 16-1498</td>\n",
       "      <td>October 30, 2018</td>\n",
       "      <td>March 19, 2019</td>\n",
       "      <td>United States Supreme Court WASHINGTON STATE D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title       Docket  \\\n",
       "0            AARON J. SCHOCK  v.  UNITED STATES(2019)   No. 18-406   \n",
       "1   ABU-ALI ABDUR'RAHMAN, ET AL.  v.  TONY PARKER,...  No. 18-8332   \n",
       "2   AIR &AMP; LIQUID SYSTEMS CORP. ET AL. v. DEVRI...  No. 17-1104   \n",
       "3   AMERICAN LEGION ET AL. v. AMERICAN HUMANIST AS...  No. 17-1717   \n",
       "4                   APPLE INC. v. PEPPER ET AL.(2019)   No. 17-204   \n",
       "..                                                ...          ...   \n",
       "62                             TIMBS v. INDIANA(2019)  No. 17-1091   \n",
       "63  VIRGINIA HOUSE OF DELEGATES ET AL. v. BETHUNE-...   No. 18-281   \n",
       "64  VIRGINIA URANIUM, INC., ET AL. v. WARREN ET AL...  No. 16-1275   \n",
       "65  WALTER DANIEL, INDIVIDUALLY AND AS PERSONAL RE...   No. 18-460   \n",
       "66  WASHINGTON STATE DEPARTMENT OF LICENSING v. CO...  No. 16-1498   \n",
       "\n",
       "               Argued            Decided  \\\n",
       "0                      February 19, 2019   \n",
       "1                           May 13, 2019   \n",
       "2    October 10, 2018     March 19, 2019   \n",
       "3   February 27, 2019      June 20, 2019   \n",
       "4   November 26, 2018       May 13, 2019   \n",
       "..                ...                ...   \n",
       "62  November 28, 2018  February 20, 2019   \n",
       "63     March 18, 2019      June 17, 2019   \n",
       "64   November 5, 2018      June 17, 2019   \n",
       "65                          May 20, 2019   \n",
       "66   October 30, 2018     March 19, 2019   \n",
       "\n",
       "                                                 Text  \n",
       "0   United States Supreme Court AARON J. SCHOCK  v...  \n",
       "1   United States Supreme Court ABU-ALI ABDUR'RAHM...  \n",
       "2   United States Supreme Court AIR &AMP; LIQUID S...  \n",
       "3   United States Supreme Court AMERICAN LEGION ET...  \n",
       "4   United States Supreme Court APPLE INC. v. PEPP...  \n",
       "..                                                ...  \n",
       "62  United States Supreme Court TIMBS v. INDIANA(2...  \n",
       "63  United States Supreme Court VIRGINIA HOUSE OF ...  \n",
       "64  United States Supreme Court VIRGINIA URANIUM, ...  \n",
       "65  United States Supreme Court WALTER DANIEL, IND...  \n",
       "66  United States Supreme Court WASHINGTON STATE D...  \n",
       "\n",
       "[67 rows x 5 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'United States Supreme Court AARON J. SCHOCK  v.  UNITED STATES(2019) No. 18-406 Argued: Decided: February 19, 2019         The petition for a writ of certiorari is denied.      Statement of Justice Sotomayor respecting the denial of certiorari.      Petitioner Aaron Schock, a former Congressman from Illinois, asks us to decide whether he may immediately appeal, as a collateral order, the denial of his motion to dismiss part of a criminal indictment against him for running afoul of the Constitution\\'s Rulemaking Clause.  See Art. I, S5.  He argues that certain charges against him would require the District Court for the Central District of Illinois to interpret internal rules adopted by the House of Representatives to govern its own Members, and thus would violate separation-of-powers doctrine.  The Court of Appeals for the Seventh Circuit held that denials of such Rulemaking Clause challenges are not collateral orders subject to immediate appeal, 891 F. 3d 334 (2018), in disagreement with at least one other Court of Appeals, see United States v. Rostenkowski, 59 F. 3d 1291, 1297 (CADC 1995).  Although this question does not arise frequently--presumably because criminal charges against Members of Congress are rare--the sensitive separation-of-powers questions that such prosecutions raise ought to be handled uniformly.      It is not clear, however, that this case cleanly presents the question whether such orders are, as a general matter, immediately appealable.  The District Court here denied the motion to dismiss on Rulemaking Clause grounds only provisionally, stating that it would revisit the matter \"if at any time it becomes apparent that the prosecution will rely upon evidence that requires the interpretation of House Rules.\"  2017 WL 4780614, *7, and n. 6 (CD Ill., Oct. 23, 2017).  Indeed, the District Court dismissed the only count of the indictment that did, in its view, necessarily turn on an interpretation of the House Rules.  Id., at *8-*11.  As a result, the District Court\\'s order may have been insufficiently \"conclusive\" to support collateral-order appellate jurisdiction, whether or not such jurisdiction would otherwise have been proper.  See Swint v. Chambers County Comm\\'n, 514 U. S. 35, 42 (1995).  The Court of Appeals did not address that alternative ground for affirmance, the presence of which might complicate our review.      I therefore concur in the Court\\'s decision to deny certiorari.  I do so on the understanding, however, that Schock remains free to reassert his Rulemaking Clause challenge in the District Court should subsequent developments warrant.*   AARON J. SCHOCK v. UNITED STATES on petition for writ of certiorari to the united states court of appeals for the seventh circuit No. 18-406. Decided February 19, 2019       The petition for a writ of certiorari is denied.      Statement of Justice Sotomayor respecting the denial of certiorari.      Petitioner Aaron Schock, a former Congressman from Illinois, asks us to decide whether he may immediately appeal, as a collateral order, the denial of his motion to dismiss part of a criminal indictment against him for running afoul of the Constitution\\'s Rulemaking Clause.  See Art. I, S5.  He argues that certain charges against him would require the District Court for the Central District of Illinois to interpret internal rules adopted by the House of Representatives to govern its own Members, and thus would violate separation-of-powers doctrine.  The Court of Appeals for the Seventh Circuit held that denials of such Rulemaking Clause challenges are not collateral orders subject to immediate appeal, 891 F. 3d 334 (2018), in disagreement with at least one other Court of Appeals, see United States v. Rostenkowski, 59 F. 3d 1291, 1297 (CADC 1995).  Although this question does not arise frequently--presumably because criminal charges against Members of Congress are rare--the sensitive separation-of-powers questions that such prosecutions raise ought to be handled uniformly.      It is not clear, however, that this case cleanly presents the question whether such orders are, as a general matter, immediately appealable.  The District Court here denied the motion to dismiss on Rulemaking Clause grounds only provisionally, stating that it would revisit the matter \"if at any time it becomes apparent that the prosecution will rely upon evidence that requires the interpretation of House Rules.\"  2017 WL 4780614, *7, and n. 6 (CD Ill., Oct. 23, 2017).  Indeed, the District Court dismissed the only count of the indictment that did, in its view, necessarily turn on an interpretation of the House Rules.  Id., at *8-*11.  As a result, the District Court\\'s order may have been insufficiently \"conclusive\" to support collateral-order appellate jurisdiction, whether or not such jurisdiction would otherwise have been proper.  See Swint v. Chambers County Comm\\'n, 514 U. S. 35, 42 (1995).  The Court of Appeals did not address that alternative ground for affirmance, the presence of which might complicate our review.      I therefore concur in the Court\\'s decision to deny certiorari.  I do so on the understanding, however, that Schock remains free to reassert his Rulemaking Clause challenge in the District Court should subsequent developments warrant.*  FOOTNOTES Footnote 1* In its briefing to the Court of Appeals, the Government argued that the House regulations were, in fact, \" \\'necessary\\' \" and \"important\" to prove other charges still pending.  Brief for Appellee in No. 17-3277 (CA7), p. 55. Those representations may be pertinent to the District Court\\'s further consideration of Schock\\'s arguments. FOOTNOTES Footnote 1* In its briefing to the Court of Appeals, the Government argued that the House regulations were, in fact, \" \\'necessary\\' \" and \"important\" to prove other charges still pending.  Brief for Appellee in No. 17-3277 (CA7), p. 55. Those representations may be pertinent to the District Court\\'s further consideration of Schock\\'s arguments.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'].head()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'United States Supreme Court AARON J. SCHOCK v. UNITED STATES(2019) No. 18-406 Argued: Decided: February 19, 2019 The petition for a writ of certiorari is denied. Statement of Justice Sotomayor respecting the denial of certiorari. Petitioner Aaron Schock, a former Congressman from Illinois, asks us to decide whether he may immediately appeal, as a collateral order, the denial of his motion to dismiss part of a criminal indictment against him for running afoul of the Constitution\\'s Rulemaking Clause. See Art. I, S5. He argues that certain charges against him would require the District Court for the Central District of Illinois to interpret internal rules adopted by the House of Representatives to govern its own Members, and thus would violate separation-of-powers doctrine. The Court of Appeals for the Seventh Circuit held that denials of such Rulemaking Clause challenges are not collateral orders subject to immediate appeal, 891 F. 3d 334 (2018), in disagreement with at least one other Court of Appeals, see United States v. Rostenkowski, 59 F. 3d 1291, 1297 (CADC 1995). Although this question does not arise frequently--presumably because criminal charges against Members of Congress are rare--the sensitive separation-of-powers questions that such prosecutions raise ought to be handled uniformly. It is not clear, however, that this case cleanly presents the question whether such orders are, as a general matter, immediately appealable. The District Court here denied the motion to dismiss on Rulemaking Clause grounds only provisionally, stating that it would revisit the matter \"if at any time it becomes apparent that the prosecution will rely upon evidence that requires the interpretation of House Rules.\" 2017 WL 4780614, *7, and n. 6 (CD Ill., October 23, 2017). Indeed, the District Court dismissed the only count of the indictment that did, in its view, necessarily turn on an interpretation of the House Rules. Id., at *8-*11. As a result, the District Court\\'s order may have been insufficiently \"conclusive\" to support collateral-order appellate jurisdiction, whether or not such jurisdiction would otherwise have been proper. See Swint v. Chambers County Comm\\'n, 514 YOU. S. 35, 42 (1995). The Court of Appeals did not address that alternative ground for affirmance, the presence of which might complicate our review. I therefore concur in the Court\\'s decision to deny certiorari. I do so on the understanding, however, that Schock remains free to reassert his Rulemaking Clause challenge in the District Court should subsequent developments warrant.* AARON J. SCHOCK v. UNITED STATES on petition for writ of certiorari to the united states court of appeals for the seventh circuit No. 18-406. Decided February 19, 2019 The petition for a writ of certiorari is denied. Statement of Justice Sotomayor respecting the denial of certiorari. Petitioner Aaron Schock, a former Congressman from Illinois, asks us to decide whether he may immediately appeal, as a collateral order, the denial of his motion to dismiss part of a criminal indictment against him for running afoul of the Constitution\\'s Rulemaking Clause. See Art. I, S5. He argues that certain charges against him would require the District Court for the Central District of Illinois to interpret internal rules adopted by the House of Representatives to govern its own Members, and thus would violate separation-of-powers doctrine. The Court of Appeals for the Seventh Circuit held that denials of such Rulemaking Clause challenges are not collateral orders subject to immediate appeal, 891 F. 3d 334 (2018), in disagreement with at least one other Court of Appeals, see United States v. Rostenkowski, 59 F. 3d 1291, 1297 (CADC 1995). Although this question does not arise frequently--presumably because criminal charges against Members of Congress are rare--the sensitive separation-of-powers questions that such prosecutions raise ought to be handled uniformly. It is not clear, however, that this case cleanly presents the question whether such orders are, as a general matter, immediately appealable. The District Court here denied the motion to dismiss on Rulemaking Clause grounds only provisionally, stating that it would revisit the matter \"if at any time it becomes apparent that the prosecution will rely upon evidence that requires the interpretation of House Rules.\" 2017 WL 4780614, *7, and n. 6 (CD Ill., October 23, 2017). Indeed, the District Court dismissed the only count of the indictment that did, in its view, necessarily turn on an interpretation of the House Rules. Id., at *8-*11. As a result, the District Court\\'s order may have been insufficiently \"conclusive\" to support collateral-order appellate jurisdiction, whether or not such jurisdiction would otherwise have been proper. See Swint v. Chambers County Comm\\'n, 514 YOU. S. 35, 42 (1995). The Court of Appeals did not address that alternative ground for affirmance, the presence of which might complicate our review. I therefore concur in the Court\\'s decision to deny certiorari. I do so on the understanding, however, that Schock remains free to reassert his Rulemaking Clause challenge in the District Court should subsequent developments warrant.* FOOTNOTES Footnote 1* In its briefing to the Court of Appeals, the Government argued that the House regulations were, in fact, \" \\'necessary\\' \" and \"important\" to prove other charges still pending. Brief for Appellee in No. 17-3277 (CA7), p. 55. Those representations may be pertinent to the District Court\\'s further consideration of Schock\\'s arguments. FOOTNOTES Footnote 1* In its briefing to the Court of Appeals, the Government argued that the House regulations were, in fact, \" \\'necessary\\' \" and \"important\" to prove other charges still pending. Brief for Appellee in No. 17-3277 (CA7), p. 55. Those representations may be pertinent to the District Court\\'s further consideration of Schock\\'s arguments.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Disabled as it might be important later on\n",
    "# # lower case\n",
    "# df['Text'] = df['Text'].str.lower()\n",
    "\n",
    "# remove url\n",
    "df['Text'] = df['Text'].str.replace(r'[\\S]+\\.(net|com|org|info|edu|gov|uk|de|ca|jp|fr|au|us|ru|ch|it|nel|se|no|es|mil)[\\S]*\\s?', 'URL', regex=True)\n",
    "\n",
    "# Disabled as legal cases need punctuations to work\n",
    "# # remove non-alphabetical\n",
    "# df['Text'] = df['Text'].str.replace('[^a-zA-Z0-9\\'\\\".!()]', ' ', regex=True).str.strip()\n",
    "\n",
    "\n",
    "# remove extra spaces\n",
    "df['Text'] = df['Text'].str.replace(' +', ' ', regex=True).str.strip()\n",
    "\n",
    "# #expand contractions\n",
    "df['Text'] = df['Text'].apply(lambda x: contractions.fix(x))\n",
    "df['Text'].head()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish base line performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # preprocess df['tokens'] using preocess_text function\n",
    "# data = df[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['tokens'] = preprocess_data(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['tokens'] = tokenize_and_remove_stopwords(df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['United',\n",
       " 'States',\n",
       " 'Supreme',\n",
       " 'Court',\n",
       " 'AARON',\n",
       " 'J.',\n",
       " 'SCHOCK',\n",
       " 'v.',\n",
       " 'UNITED',\n",
       " 'STATES',\n",
       " '(',\n",
       " '2019',\n",
       " ')',\n",
       " 'No',\n",
       " '.',\n",
       " '18-406',\n",
       " 'Argued',\n",
       " ':',\n",
       " 'Decided',\n",
       " ':',\n",
       " 'February',\n",
       " '19',\n",
       " ',',\n",
       " '2019',\n",
       " 'The',\n",
       " 'petition',\n",
       " 'writ',\n",
       " 'certiorari',\n",
       " 'denied',\n",
       " '.',\n",
       " 'Statement',\n",
       " 'Justice',\n",
       " 'Sotomayor',\n",
       " 'respecting',\n",
       " 'denial',\n",
       " 'certiorari',\n",
       " '.',\n",
       " 'Petitioner',\n",
       " 'Aaron',\n",
       " 'Schock',\n",
       " ',',\n",
       " 'former',\n",
       " 'Congressman',\n",
       " 'Illinois',\n",
       " ',',\n",
       " 'asks',\n",
       " 'us',\n",
       " 'decide',\n",
       " 'whether',\n",
       " 'may',\n",
       " 'immediately',\n",
       " 'appeal',\n",
       " ',',\n",
       " 'collateral',\n",
       " 'order',\n",
       " ',',\n",
       " 'denial',\n",
       " 'motion',\n",
       " 'dismiss',\n",
       " 'part',\n",
       " 'criminal',\n",
       " 'indictment',\n",
       " 'running',\n",
       " 'afoul',\n",
       " 'Constitution',\n",
       " \"'s\",\n",
       " 'Rulemaking',\n",
       " 'Clause',\n",
       " '.',\n",
       " 'See',\n",
       " 'Art',\n",
       " '.',\n",
       " 'I',\n",
       " ',',\n",
       " 'S5',\n",
       " '.',\n",
       " 'He',\n",
       " 'argues',\n",
       " 'certain',\n",
       " 'charges',\n",
       " 'would',\n",
       " 'require',\n",
       " 'District',\n",
       " 'Court',\n",
       " 'Central',\n",
       " 'District',\n",
       " 'Illinois',\n",
       " 'interpret',\n",
       " 'internal',\n",
       " 'rules',\n",
       " 'adopted',\n",
       " 'House',\n",
       " 'Representatives',\n",
       " 'govern',\n",
       " 'Members',\n",
       " ',',\n",
       " 'thus',\n",
       " 'would',\n",
       " 'violate',\n",
       " 'separation-of-powers',\n",
       " 'doctrine',\n",
       " '.',\n",
       " 'The',\n",
       " 'Court',\n",
       " 'Appeals',\n",
       " 'Seventh',\n",
       " 'Circuit',\n",
       " 'held',\n",
       " 'denials',\n",
       " 'Rulemaking',\n",
       " 'Clause',\n",
       " 'challenges',\n",
       " 'collateral',\n",
       " 'orders',\n",
       " 'subject',\n",
       " 'immediate',\n",
       " 'appeal',\n",
       " ',',\n",
       " '891',\n",
       " 'F.',\n",
       " '3d',\n",
       " '334',\n",
       " '(',\n",
       " '2018',\n",
       " ')',\n",
       " ',',\n",
       " 'disagreement',\n",
       " 'least',\n",
       " 'one',\n",
       " 'Court',\n",
       " 'Appeals',\n",
       " ',',\n",
       " 'see',\n",
       " 'United',\n",
       " 'States',\n",
       " 'v.',\n",
       " 'Rostenkowski',\n",
       " ',',\n",
       " '59',\n",
       " 'F.',\n",
       " '3d',\n",
       " '1291',\n",
       " ',',\n",
       " '1297',\n",
       " '(',\n",
       " 'CADC',\n",
       " '1995',\n",
       " ')',\n",
       " '.',\n",
       " 'Although',\n",
       " 'question',\n",
       " 'arise',\n",
       " 'frequently',\n",
       " '--',\n",
       " 'presumably',\n",
       " 'criminal',\n",
       " 'charges',\n",
       " 'Members',\n",
       " 'Congress',\n",
       " 'rare',\n",
       " '--',\n",
       " 'sensitive',\n",
       " 'separation-of-powers',\n",
       " 'questions',\n",
       " 'prosecutions',\n",
       " 'raise',\n",
       " 'ought',\n",
       " 'handled',\n",
       " 'uniformly',\n",
       " '.',\n",
       " 'It',\n",
       " 'clear',\n",
       " ',',\n",
       " 'however',\n",
       " ',',\n",
       " 'case',\n",
       " 'cleanly',\n",
       " 'presents',\n",
       " 'question',\n",
       " 'whether',\n",
       " 'orders',\n",
       " ',',\n",
       " 'general',\n",
       " 'matter',\n",
       " ',',\n",
       " 'immediately',\n",
       " 'appealable',\n",
       " '.',\n",
       " 'The',\n",
       " 'District',\n",
       " 'Court',\n",
       " 'denied',\n",
       " 'motion',\n",
       " 'dismiss',\n",
       " 'Rulemaking',\n",
       " 'Clause',\n",
       " 'grounds',\n",
       " 'provisionally',\n",
       " ',',\n",
       " 'stating',\n",
       " 'would',\n",
       " 'revisit',\n",
       " 'matter',\n",
       " '``',\n",
       " 'time',\n",
       " 'becomes',\n",
       " 'apparent',\n",
       " 'prosecution',\n",
       " 'rely',\n",
       " 'upon',\n",
       " 'evidence',\n",
       " 'requires',\n",
       " 'interpretation',\n",
       " 'House',\n",
       " 'Rules',\n",
       " '.',\n",
       " \"''\",\n",
       " '2017',\n",
       " 'WL',\n",
       " '4780614',\n",
       " ',',\n",
       " '*',\n",
       " '7',\n",
       " ',',\n",
       " 'n.',\n",
       " '6',\n",
       " '(',\n",
       " 'CD',\n",
       " 'Ill.',\n",
       " ',',\n",
       " 'October',\n",
       " '23',\n",
       " ',',\n",
       " '2017',\n",
       " ')',\n",
       " '.',\n",
       " 'Indeed',\n",
       " ',',\n",
       " 'District',\n",
       " 'Court',\n",
       " 'dismissed',\n",
       " 'count',\n",
       " 'indictment',\n",
       " ',',\n",
       " 'view',\n",
       " ',',\n",
       " 'necessarily',\n",
       " 'turn',\n",
       " 'interpretation',\n",
       " 'House',\n",
       " 'Rules',\n",
       " '.',\n",
       " 'Id.',\n",
       " ',',\n",
       " '*',\n",
       " '8-',\n",
       " '*',\n",
       " '11',\n",
       " '.',\n",
       " 'As',\n",
       " 'result',\n",
       " ',',\n",
       " 'District',\n",
       " 'Court',\n",
       " \"'s\",\n",
       " 'order',\n",
       " 'may',\n",
       " 'insufficiently',\n",
       " '``',\n",
       " 'conclusive',\n",
       " \"''\",\n",
       " 'support',\n",
       " 'collateral-order',\n",
       " 'appellate',\n",
       " 'jurisdiction',\n",
       " ',',\n",
       " 'whether',\n",
       " 'jurisdiction',\n",
       " 'would',\n",
       " 'otherwise',\n",
       " 'proper',\n",
       " '.',\n",
       " 'See',\n",
       " 'Swint',\n",
       " 'v.',\n",
       " 'Chambers',\n",
       " 'County',\n",
       " \"Comm'n\",\n",
       " ',',\n",
       " '514',\n",
       " 'YOU',\n",
       " '.',\n",
       " 'S.',\n",
       " '35',\n",
       " ',',\n",
       " '42',\n",
       " '(',\n",
       " '1995',\n",
       " ')',\n",
       " '.',\n",
       " 'The',\n",
       " 'Court',\n",
       " 'Appeals',\n",
       " 'address',\n",
       " 'alternative',\n",
       " 'ground',\n",
       " 'affirmance',\n",
       " ',',\n",
       " 'presence',\n",
       " 'might',\n",
       " 'complicate',\n",
       " 'review',\n",
       " '.',\n",
       " 'I',\n",
       " 'therefore',\n",
       " 'concur',\n",
       " 'Court',\n",
       " \"'s\",\n",
       " 'decision',\n",
       " 'deny',\n",
       " 'certiorari',\n",
       " '.',\n",
       " 'I',\n",
       " 'understanding',\n",
       " ',',\n",
       " 'however',\n",
       " ',',\n",
       " 'Schock',\n",
       " 'remains',\n",
       " 'free',\n",
       " 'reassert',\n",
       " 'Rulemaking',\n",
       " 'Clause',\n",
       " 'challenge',\n",
       " 'District',\n",
       " 'Court',\n",
       " 'subsequent',\n",
       " 'developments',\n",
       " 'warrant',\n",
       " '.',\n",
       " '*',\n",
       " 'AARON',\n",
       " 'J.',\n",
       " 'SCHOCK',\n",
       " 'v.',\n",
       " 'UNITED',\n",
       " 'STATES',\n",
       " 'petition',\n",
       " 'writ',\n",
       " 'certiorari',\n",
       " 'united',\n",
       " 'states',\n",
       " 'court',\n",
       " 'appeals',\n",
       " 'seventh',\n",
       " 'circuit',\n",
       " 'No',\n",
       " '.',\n",
       " '18-406',\n",
       " '.',\n",
       " 'Decided',\n",
       " 'February',\n",
       " '19',\n",
       " ',',\n",
       " '2019',\n",
       " 'The',\n",
       " 'petition',\n",
       " 'writ',\n",
       " 'certiorari',\n",
       " 'denied',\n",
       " '.',\n",
       " 'Statement',\n",
       " 'Justice',\n",
       " 'Sotomayor',\n",
       " 'respecting',\n",
       " 'denial',\n",
       " 'certiorari',\n",
       " '.',\n",
       " 'Petitioner',\n",
       " 'Aaron',\n",
       " 'Schock',\n",
       " ',',\n",
       " 'former',\n",
       " 'Congressman',\n",
       " 'Illinois',\n",
       " ',',\n",
       " 'asks',\n",
       " 'us',\n",
       " 'decide',\n",
       " 'whether',\n",
       " 'may',\n",
       " 'immediately',\n",
       " 'appeal',\n",
       " ',',\n",
       " 'collateral',\n",
       " 'order',\n",
       " ',',\n",
       " 'denial',\n",
       " 'motion',\n",
       " 'dismiss',\n",
       " 'part',\n",
       " 'criminal',\n",
       " 'indictment',\n",
       " 'running',\n",
       " 'afoul',\n",
       " 'Constitution',\n",
       " \"'s\",\n",
       " 'Rulemaking',\n",
       " 'Clause',\n",
       " '.',\n",
       " 'See',\n",
       " 'Art',\n",
       " '.',\n",
       " 'I',\n",
       " ',',\n",
       " 'S5',\n",
       " '.',\n",
       " 'He',\n",
       " 'argues',\n",
       " 'certain',\n",
       " 'charges',\n",
       " 'would',\n",
       " 'require',\n",
       " 'District',\n",
       " 'Court',\n",
       " 'Central',\n",
       " 'District',\n",
       " 'Illinois',\n",
       " 'interpret',\n",
       " 'internal',\n",
       " 'rules',\n",
       " 'adopted',\n",
       " 'House',\n",
       " 'Representatives',\n",
       " 'govern',\n",
       " 'Members',\n",
       " ',',\n",
       " 'thus',\n",
       " 'would',\n",
       " 'violate',\n",
       " 'separation-of-powers',\n",
       " 'doctrine',\n",
       " '.',\n",
       " 'The',\n",
       " 'Court',\n",
       " 'Appeals',\n",
       " 'Seventh',\n",
       " 'Circuit',\n",
       " 'held',\n",
       " 'denials',\n",
       " 'Rulemaking',\n",
       " 'Clause',\n",
       " 'challenges',\n",
       " 'collateral',\n",
       " 'orders',\n",
       " 'subject',\n",
       " 'immediate',\n",
       " 'appeal',\n",
       " ',',\n",
       " '891',\n",
       " 'F.',\n",
       " '3d',\n",
       " '334',\n",
       " '(',\n",
       " '2018',\n",
       " ')',\n",
       " ',',\n",
       " 'disagreement',\n",
       " 'least',\n",
       " 'one',\n",
       " 'Court',\n",
       " 'Appeals',\n",
       " ',',\n",
       " 'see',\n",
       " 'United',\n",
       " 'States',\n",
       " 'v.',\n",
       " 'Rostenkowski',\n",
       " ',',\n",
       " '59',\n",
       " 'F.',\n",
       " '3d',\n",
       " '1291',\n",
       " ',',\n",
       " '1297',\n",
       " '(',\n",
       " 'CADC',\n",
       " '1995',\n",
       " ')',\n",
       " '.',\n",
       " 'Although',\n",
       " 'question',\n",
       " 'arise',\n",
       " 'frequently',\n",
       " '--',\n",
       " 'presumably',\n",
       " 'criminal',\n",
       " 'charges',\n",
       " 'Members',\n",
       " 'Congress',\n",
       " 'rare',\n",
       " '--',\n",
       " 'sensitive',\n",
       " 'separation-of-powers',\n",
       " 'questions',\n",
       " 'prosecutions',\n",
       " 'raise',\n",
       " 'ought',\n",
       " 'handled',\n",
       " 'uniformly',\n",
       " '.',\n",
       " 'It',\n",
       " 'clear',\n",
       " ',',\n",
       " 'however',\n",
       " ',',\n",
       " 'case',\n",
       " 'cleanly',\n",
       " 'presents',\n",
       " 'question',\n",
       " 'whether',\n",
       " 'orders',\n",
       " ',',\n",
       " 'general',\n",
       " 'matter',\n",
       " ',',\n",
       " 'immediately',\n",
       " 'appealable',\n",
       " '.',\n",
       " 'The',\n",
       " 'District',\n",
       " 'Court',\n",
       " 'denied',\n",
       " 'motion',\n",
       " 'dismiss',\n",
       " 'Rulemaking',\n",
       " 'Clause',\n",
       " 'grounds',\n",
       " 'provisionally',\n",
       " ',',\n",
       " 'stating',\n",
       " 'would',\n",
       " 'revisit',\n",
       " 'matter',\n",
       " '``',\n",
       " 'time',\n",
       " 'becomes',\n",
       " 'apparent',\n",
       " 'prosecution',\n",
       " 'rely',\n",
       " 'upon',\n",
       " 'evidence',\n",
       " 'requires',\n",
       " 'interpretation',\n",
       " 'House',\n",
       " 'Rules',\n",
       " '.',\n",
       " \"''\",\n",
       " '2017',\n",
       " 'WL',\n",
       " '4780614',\n",
       " ',',\n",
       " '*',\n",
       " '7',\n",
       " ',',\n",
       " 'n.',\n",
       " '6',\n",
       " '(',\n",
       " 'CD',\n",
       " 'Ill.',\n",
       " ',',\n",
       " 'October',\n",
       " '23',\n",
       " ',',\n",
       " '2017',\n",
       " ')',\n",
       " '.',\n",
       " 'Indeed',\n",
       " ',',\n",
       " 'District',\n",
       " 'Court',\n",
       " 'dismissed',\n",
       " 'count',\n",
       " 'indictment',\n",
       " ',',\n",
       " 'view',\n",
       " ',',\n",
       " 'necessarily',\n",
       " 'turn',\n",
       " 'interpretation',\n",
       " 'House',\n",
       " 'Rules',\n",
       " '.',\n",
       " 'Id.',\n",
       " ',',\n",
       " '*',\n",
       " '8-',\n",
       " '*',\n",
       " '11',\n",
       " '.',\n",
       " 'As',\n",
       " 'result',\n",
       " ',',\n",
       " 'District',\n",
       " 'Court',\n",
       " \"'s\",\n",
       " 'order',\n",
       " 'may',\n",
       " 'insufficiently',\n",
       " '``',\n",
       " 'conclusive',\n",
       " \"''\",\n",
       " 'support',\n",
       " 'collateral-order',\n",
       " 'appellate',\n",
       " 'jurisdiction',\n",
       " ',',\n",
       " 'whether',\n",
       " 'jurisdiction',\n",
       " 'would',\n",
       " 'otherwise',\n",
       " 'proper',\n",
       " '.',\n",
       " 'See',\n",
       " 'Swint',\n",
       " 'v.',\n",
       " 'Chambers',\n",
       " 'County',\n",
       " \"Comm'n\",\n",
       " ',',\n",
       " '514',\n",
       " 'YOU',\n",
       " '.',\n",
       " 'S.',\n",
       " '35',\n",
       " ',',\n",
       " '42',\n",
       " '(',\n",
       " '1995',\n",
       " ')',\n",
       " '.',\n",
       " 'The',\n",
       " 'Court',\n",
       " 'Appeals',\n",
       " 'address',\n",
       " 'alternative',\n",
       " 'ground',\n",
       " 'affirmance',\n",
       " ',',\n",
       " 'presence',\n",
       " 'might',\n",
       " 'complicate',\n",
       " 'review',\n",
       " '.',\n",
       " 'I',\n",
       " 'therefore',\n",
       " 'concur',\n",
       " 'Court',\n",
       " \"'s\",\n",
       " 'decision',\n",
       " 'deny',\n",
       " 'certiorari',\n",
       " '.',\n",
       " 'I',\n",
       " 'understanding',\n",
       " ',',\n",
       " 'however',\n",
       " ',',\n",
       " 'Schock',\n",
       " 'remains',\n",
       " 'free',\n",
       " 'reassert',\n",
       " 'Rulemaking',\n",
       " 'Clause',\n",
       " 'challenge',\n",
       " 'District',\n",
       " 'Court',\n",
       " 'subsequent',\n",
       " 'developments',\n",
       " 'warrant',\n",
       " '.',\n",
       " '*',\n",
       " 'FOOTNOTES',\n",
       " 'Footnote',\n",
       " '1',\n",
       " '*',\n",
       " 'In',\n",
       " 'briefing',\n",
       " 'Court',\n",
       " 'Appeals',\n",
       " ',',\n",
       " 'Government',\n",
       " 'argued',\n",
       " 'House',\n",
       " 'regulations',\n",
       " ',',\n",
       " 'fact',\n",
       " ',',\n",
       " '``',\n",
       " \"'necessary\",\n",
       " \"'\",\n",
       " '``',\n",
       " '``',\n",
       " 'important',\n",
       " \"''\",\n",
       " 'prove',\n",
       " 'charges',\n",
       " 'still',\n",
       " 'pending',\n",
       " '.',\n",
       " 'Brief',\n",
       " 'Appellee',\n",
       " 'No',\n",
       " '.',\n",
       " '17-3277',\n",
       " '(',\n",
       " 'CA7',\n",
       " ')',\n",
       " ',',\n",
       " 'p.',\n",
       " '55',\n",
       " '.',\n",
       " 'Those',\n",
       " 'representations',\n",
       " 'may',\n",
       " 'pertinent',\n",
       " 'District',\n",
       " 'Court',\n",
       " \"'s\",\n",
       " 'consideration',\n",
       " 'Schock',\n",
       " \"'s\",\n",
       " 'arguments',\n",
       " '.',\n",
       " 'FOOTNOTES',\n",
       " 'Footnote',\n",
       " '1',\n",
       " '*',\n",
       " 'In',\n",
       " 'briefing',\n",
       " 'Court',\n",
       " 'Appeals',\n",
       " ',',\n",
       " 'Government',\n",
       " 'argued',\n",
       " 'House',\n",
       " 'regulations',\n",
       " ',',\n",
       " 'fact',\n",
       " ',',\n",
       " '``',\n",
       " \"'necessary\",\n",
       " \"'\",\n",
       " '``',\n",
       " '``',\n",
       " 'important',\n",
       " \"''\",\n",
       " 'prove',\n",
       " 'charges',\n",
       " 'still',\n",
       " 'pending',\n",
       " '.',\n",
       " 'Brief',\n",
       " 'Appellee',\n",
       " 'No',\n",
       " '.',\n",
       " '17-3277',\n",
       " '(',\n",
       " 'CA7',\n",
       " ')',\n",
       " ',',\n",
       " 'p.',\n",
       " '55',\n",
       " '.',\n",
       " 'Those',\n",
       " 'representations',\n",
       " 'may',\n",
       " 'pertinent',\n",
       " 'District',\n",
       " 'Court',\n",
       " \"'s\",\n",
       " 'consideration',\n",
       " 'Schock',\n",
       " \"'s\",\n",
       " 'arguments',\n",
       " '.']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "df['tokens'] = df['Text'].apply(tokenize.word_tokenize)\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "df['tokens'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [(United, NNP), (States, NNPS), (Supreme, NNP)...\n",
       "1     [(United, NNP), (States, NNPS), (Supreme, NNP)...\n",
       "2     [(United, NNP), (States, NNPS), (Supreme, NNP)...\n",
       "3     [(United, NNP), (States, NNPS), (Supreme, NNP)...\n",
       "4     [(United, NNP), (States, NNPS), (Supreme, NNP)...\n",
       "                            ...                        \n",
       "62    [(United, NNP), (States, NNPS), (Supreme, NNP)...\n",
       "63    [(United, NNP), (States, NNPS), (Supreme, NNP)...\n",
       "64    [(United, NNP), (States, NNPS), (Supreme, NNP)...\n",
       "65    [(United, NNP), (States, NNPS), (Supreme, NNP)...\n",
       "66    [(United, NNP), (States, NNPS), (Supreme, NNP)...\n",
       "Name: tokens, Length: 67, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'] = df['tokens'].apply(nltk.tag.pos_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['tokens'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [lemma.lemmatize(word, tag) for word, tag in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = [' '.join(map(str, l)) for l in df['tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize the text using tfidf vectorizer\n",
    "X_data = vectorize_tfidf(df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 434)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(df['tokens'], vector_size=300, window=5, min_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word2vec_embeddings(X):\n",
    "    embeddings = []\n",
    "    for sentence in X:\n",
    "        sentence_embedding = np.zeros(300)\n",
    "        for word in sentence:\n",
    "            if word in w2v_model.wv:\n",
    "                sentence_embedding += w2v_model.wv[word]\n",
    "        embeddings.append(sentence_embedding)\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_vectors = create_word2vec_embeddings(df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 300)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api\n",
    "\n",
    "def tagged_document(list_of_list_of_words):\n",
    "   for i, list_of_words in enumerate(list_of_list_of_words):\n",
    "      yield gensim.models.doc2vec.TaggedDocument(list_of_words, [i])\n",
    "\n",
    "def doc2vec_vectors(X):\n",
    "    documents = list(tagged_document(X[0].split()))\n",
    "    model = gensim.models.doc2vec.Doc2Vec(documents, vector_size=300, window=5, min_count=10)\n",
    "    return np.array([model.infer_vector(doc.split()) for doc in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec = doc2vec_vectors(df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 5, 4, 8], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find most similar cases using cosine similarity and tfidf vectors\n",
    "def find_similar_cases(X, case_id, n):\n",
    "    pairwise_similarities=np.dot(X,X.T)\n",
    "    most_similar = pairwise_similarities[case_id].argsort()[:-n-1:-1]\n",
    "    return most_similar\n",
    "\n",
    "#find most similar cases using cosine similarity and word2vec vectors\n",
    "\n",
    "find_similar_cases(X_data, 0, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "#find the max sequence length of word2vec vectors\\\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(df['tokens'])\n",
    "tokenized_documents=tokenizer.texts_to_sequences(df['tokens'])\n",
    "tokenized_paded_documents=pad_sequences(tokenized_documents,maxlen=5000,padding='post')\n",
    "vocab_size=len(tokenizer.word_index)+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_vectors = create_word2vec_embeddings(df['tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "     ---------------------------------------- 86.0/86.0 kB 2.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 5.5/5.5 MB 8.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\akish\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from sentence-transformers) (4.64.1)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-1.13.0-cp39-cp39-win_amd64.whl (167.2 MB)\n",
      "     -------------------------------------- 167.2/167.2 MB 6.5 MB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.14.0-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 11.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\akish\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from sentence-transformers) (1.22.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\akish\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from sentence-transformers) (1.1.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\akish\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\akish\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from sentence-transformers) (3.7)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 10.2 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub>=0.4.0\n",
      "  Using cached huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\akish\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\akish\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\akish\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp39-cp39-win_amd64.whl (151 kB)\n",
      "     -------------------------------------- 151.6/151.6 kB 8.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\akish\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.9.13)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.1-cp39-cp39-win_amd64.whl (3.3 MB)\n",
      "Requirement already satisfied: colorama in c:\\users\\akish\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: click in c:\\users\\akish\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from nltk->sentence-transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\akish\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from nltk->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\akish\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading Pillow-9.3.0-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 9.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\akish\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\akish\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\akish\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\akish\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\akish\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.11)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125930 sha256=695baba5210bbbaf5df1b9d4bb5ab3754c05bb66f78afacf770b8cb2529f2050\n",
      "  Stored in directory: c:\\users\\akish\\appdata\\local\\pip\\cache\\wheels\\71\\67\\06\\162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, torch, pyyaml, pillow, filelock, torchvision, huggingface-hub, transformers, sentence-transformers\n",
      "Successfully installed filelock-3.8.0 huggingface-hub-0.10.1 pillow-9.3.0 pyyaml-6.0 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.1 torch-1.13.0 torchvision-0.14.0 transformers-4.24.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3edad09936df4063b89126814b97e921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/391 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb936b448fb4c70b33e42c6c9b17284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96db27524f34a1c87011b13b0a0cbf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86964e22e4b473a97968484a3842017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d6741d71fc4238b4d3a9bb343d2da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6887908f6f49e99bb2a66d1321beed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e81bcd73314d24ab5acd8658c18adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a45f2cbb1f4fda88223815732531d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de48eebdbaea4ff686e29aec3a495595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da9d12ae7c7482a9c4ffa89e7a5e812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e510ef4d33484d3293bc531166b54f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857f237f81364c748f8ab65dcb3502b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041f48592561473eb7ff900ee413a3ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "! pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "sentence_embeddings = model.encode(df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similar = cosine_similarity(\n",
    "    [sentence_embeddings[0]],\n",
    "    sentence_embeddings[:]\n",
    ")\n",
    "ind = np.argsort(similar[0])[::-1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 98,  2,  7, 88], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e66561729588fc2fcb09d28710c33ed3600fb4199061a7dd168c5260d84c0181"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
